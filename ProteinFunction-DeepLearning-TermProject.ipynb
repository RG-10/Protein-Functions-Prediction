{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8823b61a",
   "metadata": {},
   "source": [
    "# Protein Function Prediction through Amino Acid Sequences\n",
    "\n",
    "  >**Usama Raheem 19011519-002** |\n",
    "  >**Usama Saeed  19011519-003**  |\n",
    "  >**Qaseem Hussain 19011519-031** \n",
    "\n",
    "## Goal\n",
    "Classification of protein function based on their sequences. \n",
    "\n",
    "**The protein function  which the project focusses is the ATP binding.**\n",
    "\n",
    "\n",
    "# Data collection\n",
    "\n",
    "Data scraping was performed on several protein sequence and their function from biological databases mainly [Unitprot](https://www.uniprot.org/uniprot/P03960).\n",
    "\n",
    ">**data-scrapes** contains the sequence in the fasta format and annotation of the various proteins.\n",
    "\n",
    "# Approach \n",
    "The sequence of the protein were augmented after 500 residues. The sequences, which had lower length were artifically padded with '_'.\n",
    "We used Artifical Neural Network (ANN) to classify the protein function (obtained after hyperparameter tuninng) :  \n",
    "\n",
    "|     Method    |   Numbers\n",
    "| ------------- | ------------- |\n",
    "|      ANN    | 2/3  layers |\n",
    "| Embedding dim  | 10      |\n",
    "| Sequence length | 23 |\n",
    "| Optimizer     | Stochastic Gradient Descent (SGD)   |\n",
    "| Loss | Binary crossentropy | \n",
    "| Nodes | 128|\n",
    "|Batch size | 128 |\n",
    "|Learning Rate | 0.001 |\n",
    "|Accuracy Score | 0.80 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1c4dc2",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed0da3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import yaml\n",
    "sns.set()\n",
    "from Bio import SeqIO\n",
    "from tensorflow.keras.preprocessing import sequence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2849b1eb",
   "metadata": {},
   "source": [
    "# Scraping/Extracting Sequence from txt File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bbaa30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re   \n",
    "import os\n",
    "import glob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "471c622f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RG\\Desktop\\FYP-2023\\DL-project\\data-scrapes\n"
     ]
    }
   ],
   "source": [
    "scrape_dir = os.path.join(r'C:\\Users\\RG\\Desktop\\FYP-2023\\DL-project', 'data-scrapes')\n",
    "print(scrape_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc51033e",
   "metadata": {},
   "source": [
    "### Writing Scrapped data in File named protein-seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ce661a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting sequences ... \n",
      "Writing to: C:\\Users\\RG\\Desktop\\FYP-2023\\DL-project\\data\\protein-seqs-2023-02-19-211801.txt\n"
     ]
    }
   ],
   "source": [
    "import datetime, time\n",
    "ts = time.time()\n",
    "st = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d-%H%M%S')\n",
    "\n",
    "print(\"Converting sequences ... \")\n",
    "out_file = os.path.join(r'C:\\Users\\RG\\Desktop\\FYP-2023\\DL-project', 'data', 'protein-seqs-' + st + '.txt')\n",
    "\n",
    "print(\"Writing to: %s\" % out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c752cb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\RG\\\\Desktop\\\\FYP-2023\\\\DL-project\\\\data-scrapes\\\\all-human-0001.fasta']\n"
     ]
    }
   ],
   "source": [
    "num_proteins_done = 50\n",
    "fasta_files = glob.glob(scrape_dir + \"/*.fasta\") \n",
    "print(fasta_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b833de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_to_file(protein_id, sequence):\n",
    "    with open(out_file, \"a\") as f:\n",
    "        f.write(protein_id + \",\" + sequence + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb045869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting: C:\\Users\\RG\\Desktop\\FYP-2023\\DL-project\\data-scrapes\\all-human-0001.fasta: \n"
     ]
    }
   ],
   "source": [
    "for fname in fasta_files:\n",
    "    print(\"Converting: %s: \" % fname)\n",
    "    proteins = {}   \n",
    "    with open (fname, 'r') as f:\n",
    "        protein_seq = ''\n",
    "        protein_id = ''\n",
    "        for line in f:    \n",
    "            match = re.search(r'^>([a-z]{2})\\|([A-Z0-9]*)\\|', line) \n",
    "            if match:\n",
    "                if protein_id != '': \n",
    "                    dump_to_file(protein_id, protein_seq)   \n",
    "                num_proteins_done += 1 \n",
    "                if num_proteins_done > 10: break   \n",
    "                protein_id = match.group(2)\n",
    "                protein_seq = ''   \n",
    "            else:\n",
    "                protein_seq += line.strip() \n",
    "        if protein_id != '': \n",
    "            dump_to_file(protein_id, protein_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d43dc546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting functions ...\n",
      "C:\\Users\\RG\\Desktop\\FYP-2023\\DL-project\\data\\protein-functions-2023-02-19-211801.txt\n"
     ]
    }
   ],
   "source": [
    "print(\"Converting functions ...\") \n",
    "out_file_fns = os.path.join(r'C:\\Users\\RG\\Desktop\\FYP-2023\\DL-project', 'data', 'protein-functions-' + st + '.txt')\n",
    "print(out_file_fns)\n",
    "target_functions = ['0005524']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b2a2988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\RG\\\\Desktop\\\\FYP-2023\\\\DL-project\\\\data-scrapes\\\\all-human-0001-annotations.txt']\n"
     ]
    }
   ],
   "source": [
    "annot_files = glob.glob(scrape_dir + \"/*annotations.txt\")\n",
    "print(annot_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cd6103f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P27361', 'P53779', 'Q9UHC1', 'Q9NYL2', 'O15440', 'P33527', 'Q92887', 'O15438', 'O15439', 'Q5T3U5']\n"
     ]
    }
   ],
   "source": [
    "has_function = [] \n",
    "\n",
    "for fname in annot_files:\n",
    "    with open (fname, 'r') as f:\n",
    "        for line in f:\n",
    "            match = re.search(r'([A-Z0-9]*)\\sGO:(.*);\\sF:.*;', line)\n",
    "            if match:\n",
    "                # we got the match correctly (should always happen)\n",
    "                protein_id = match.group(1)\n",
    "                function = match.group(2)\n",
    "                \n",
    "                if function not in target_functions:\n",
    "                        continue\n",
    "                        \n",
    "                # We found the function for this protein, so the class will be 'True'\n",
    "                has_function.append(protein_id) \n",
    "          \n",
    "    import json\n",
    "    with open(out_file_fns, 'w') as fp:\n",
    "        json.dump(has_function, fp)\n",
    "        \n",
    "    print(has_function[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82228409",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a071a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os \n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80c038bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_file = os.path.join(r'C:\\Users\\RG\\Desktop\\FYP-2023\\DL-project', 'data', 'protein-seqs-1.txt')\n",
    "functions_file = os.path.join(r'C:\\Users\\RG\\Desktop\\FYP-2023\\DL-project', 'data', 'protein-functions-1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df853913",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(functions_file) as fn_file:\n",
    "    has_function = json.load(fn_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06c10b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['P27361',\n",
       " 'P53779',\n",
       " 'Q9UHC1',\n",
       " 'Q9NYL2',\n",
       " 'O15440',\n",
       " 'P33527',\n",
       " 'Q92887',\n",
       " 'O15438',\n",
       " 'O15439',\n",
       " 'Q5T3U5',\n",
       " 'P42345',\n",
       " 'O75648',\n",
       " 'Q16659',\n",
       " 'Q8NB16',\n",
       " 'Q02750',\n",
       " 'O95255',\n",
       " 'O95396',\n",
       " 'O43196',\n",
       " 'P46734',\n",
       " 'P49914',\n",
       " 'Q6DT37',\n",
       " 'Q9H3H1',\n",
       " 'Q9HCE1',\n",
       " 'P52564',\n",
       " 'Q9Y5S2',\n",
       " 'Q96J65',\n",
       " 'P20585',\n",
       " 'O15457',\n",
       " 'P52701',\n",
       " 'Q5VT25',\n",
       " 'A7E2Y1',\n",
       " 'Q9UKN7',\n",
       " 'Q9Y6X6',\n",
       " 'Q96MN2',\n",
       " 'P13535',\n",
       " 'Q32MK0',\n",
       " 'O43795',\n",
       " 'O00159',\n",
       " 'Q9UM54',\n",
       " 'Q13402',\n",
       " 'Q9UKX2',\n",
       " 'P13533',\n",
       " 'Q9H1R3',\n",
       " 'Q8WXR4',\n",
       " 'Q6PIF6',\n",
       " 'B2RTY4',\n",
       " 'Q6IA69',\n",
       " 'Q86W25',\n",
       " 'Q9UKX3',\n",
       " 'Q7Z406',\n",
       " 'P12882',\n",
       " 'Q15746',\n",
       " 'O15146',\n",
       " 'Q9Y623',\n",
       " 'P12883',\n",
       " 'P35579',\n",
       " 'B0I1T2',\n",
       " 'Q9Y4I1',\n",
       " 'Q96JP2',\n",
       " 'Q8IUG5',\n",
       " 'Q9UBC5',\n",
       " 'O00160',\n",
       " 'P53602',\n",
       " 'Q92614',\n",
       " 'P35749',\n",
       " 'P11055',\n",
       " 'Q9Y2K3',\n",
       " 'Q86YV6',\n",
       " 'Q9HD67',\n",
       " 'Q8N1T3',\n",
       " 'Q9ULV0',\n",
       " 'Q13459',\n",
       " 'Q86W26',\n",
       " 'P59046',\n",
       " 'Q9UJ70',\n",
       " 'Q86W24',\n",
       " 'Q13232',\n",
       " 'Q9H0A0',\n",
       " 'P22392',\n",
       " 'Q8IY84',\n",
       " 'Q86WI3',\n",
       " 'Q96P20',\n",
       " 'Q86UW6',\n",
       " 'Q8IVL1',\n",
       " 'O75414',\n",
       " 'Q8NG66',\n",
       " 'Q96PY6',\n",
       " 'P35580',\n",
       " 'Q96H55',\n",
       " 'O94832',\n",
       " 'Q12965',\n",
       " 'Q8NEV4',\n",
       " 'Q9NQX4',\n",
       " 'O95544',\n",
       " 'O60361',\n",
       " 'O00746',\n",
       " 'Q9NX02',\n",
       " 'Q8WX94',\n",
       " 'Q86W28',\n",
       " 'Q8IVL0',\n",
       " 'P15531',\n",
       " 'Q86SG6',\n",
       " 'Q9HC98',\n",
       " 'Q8TD19',\n",
       " 'Q4G0N4',\n",
       " 'P59045',\n",
       " 'P59047',\n",
       " 'Q7RTR0',\n",
       " 'Q9Y5B8',\n",
       " 'Q6P3R8',\n",
       " 'Q8TDX7',\n",
       " 'Q6ZWH5',\n",
       " 'P51955',\n",
       " 'Q86UT6',\n",
       " 'P51956',\n",
       " 'Q9UBE8',\n",
       " 'Q7RTR2',\n",
       " 'Q9NPP4',\n",
       " 'Q9BZQ4',\n",
       " 'P59044',\n",
       " 'Q8IW45',\n",
       " 'Q9HC29',\n",
       " 'Q9NPI5',\n",
       " 'Q9HAN9',\n",
       " 'Q5SY16',\n",
       " 'Q96T66',\n",
       " 'Q9Y239',\n",
       " 'Q9P0J0',\n",
       " 'P51957',\n",
       " 'Q14978',\n",
       " 'Q9C000',\n",
       " 'Q9UHY1',\n",
       " 'P46459',\n",
       " 'Q9BSD7',\n",
       " 'Q8TB37',\n",
       " 'Q16620',\n",
       " 'Q149M9',\n",
       " 'P29728',\n",
       " 'Q9H093',\n",
       " 'P04629',\n",
       " 'O60285',\n",
       " 'P53384',\n",
       " 'Q9Y5Y2',\n",
       " 'Q7Z2Y5',\n",
       " 'Q9NSY0',\n",
       " 'Q9NWW6',\n",
       " 'Q16288',\n",
       " 'O43929',\n",
       " 'O15381',\n",
       " 'Q15646',\n",
       " 'Q9NTK5',\n",
       " 'P00973',\n",
       " 'Q9Y6K5',\n",
       " 'Q5VST9',\n",
       " 'O43913',\n",
       " 'Q13415',\n",
       " 'Q9UBL9',\n",
       " 'P47900',\n",
       " 'P51582',\n",
       " 'O00443',\n",
       " 'O95747',\n",
       " 'O00750',\n",
       " 'P04637',\n",
       " 'P51575',\n",
       " 'Q9NVV4',\n",
       " 'Q96RG2',\n",
       " 'O14841',\n",
       " 'P54886',\n",
       " 'Q58A45',\n",
       " 'Q13177',\n",
       " 'O96013',\n",
       " 'Q99571',\n",
       " 'O15547',\n",
       " 'O75747',\n",
       " 'Q8TCG2',\n",
       " 'O75914',\n",
       " 'Q9P286',\n",
       " 'Q8TE04',\n",
       " 'Q9NVE7',\n",
       " 'P51003',\n",
       " 'Q9BWT3',\n",
       " 'O95340',\n",
       " 'Q13153',\n",
       " 'Q9NQU5',\n",
       " 'Q9H999',\n",
       " 'Q9NRJ5',\n",
       " 'A6NDB9',\n",
       " 'P09619',\n",
       " 'P00558',\n",
       " 'P07205',\n",
       " 'P05166',\n",
       " 'P16234',\n",
       " 'P05165',\n",
       " 'Q15645',\n",
       " 'Q15119',\n",
       " 'O15530',\n",
       " 'Q9H792',\n",
       " 'Q96RR1',\n",
       " 'P56373',\n",
       " 'Q93086',\n",
       " 'Q99572',\n",
       " 'Q9BTU6',\n",
       " 'Q9BZ23',\n",
       " 'O00764',\n",
       " 'P30086',\n",
       " 'Q15120',\n",
       " 'Q6A1A2',\n",
       " 'Q9NTI5',\n",
       " 'Q8IZE3',\n",
       " 'O43252',\n",
       " 'O60331',\n",
       " 'Q9NP80',\n",
       " 'P42336',\n",
       " 'Q504Y2',\n",
       " 'P53350',\n",
       " 'P48426',\n",
       " 'Q9UBF8',\n",
       " 'O14986',\n",
       " 'P11309',\n",
       " 'Q16512',\n",
       " 'Q9H4B4',\n",
       " 'O00444',\n",
       " 'Q96T60',\n",
       " 'P54277',\n",
       " 'P54278',\n",
       " 'Q15126',\n",
       " 'Q99640',\n",
       " 'Q6P5Z2',\n",
       " 'Q9BXM7',\n",
       " 'Q8NEB9',\n",
       " 'Q496M5',\n",
       " 'O43930',\n",
       " 'Q96S44',\n",
       " 'P11908',\n",
       " 'P17980',\n",
       " 'P43686',\n",
       " 'P53041',\n",
       " 'P51817',\n",
       " 'P21108',\n",
       " 'P62191',\n",
       " 'Q92620',\n",
       " 'P11498',\n",
       " 'Q92878',\n",
       " 'O75771',\n",
       " 'O75943',\n",
       " 'Q92698',\n",
       " 'Q9Y620',\n",
       " 'O43502',\n",
       " 'P04049',\n",
       " 'Q9H477',\n",
       " 'P22102',\n",
       " 'Q8IV42',\n",
       " 'Q13882',\n",
       " 'P35998',\n",
       " 'P62195',\n",
       " 'P78527',\n",
       " 'Q13523',\n",
       " 'P60891',\n",
       " 'P62333',\n",
       " 'P27708',\n",
       " 'Q13308',\n",
       " 'Q15257',\n",
       " 'O15067',\n",
       " 'P06737',\n",
       " 'P22234',\n",
       " 'Q9NRF8',\n",
       " 'P17812',\n",
       " 'O15315',\n",
       " 'Q06609',\n",
       " 'Q9BVS4',\n",
       " 'O43353',\n",
       " 'P46063',\n",
       " 'P51606',\n",
       " 'P57078',\n",
       " 'O94761',\n",
       " 'O94762',\n",
       " 'Q15835',\n",
       " 'P35250',\n",
       " 'P07949',\n",
       " 'P40937',\n",
       " 'O94955',\n",
       " 'Q9ULI2',\n",
       " 'Q92900',\n",
       " 'P35251',\n",
       " 'P35249',\n",
       " 'Q8IXN7',\n",
       " 'Q13546',\n",
       " 'Q969G6',\n",
       " 'Q9BRS2',\n",
       " 'O14730',\n",
       " 'Q9Y572',\n",
       " 'P23921',\n",
       " 'Q05823',\n",
       " 'Q13464',\n",
       " 'Q04912',\n",
       " 'Q9Y6S9',\n",
       " 'O75116',\n",
       " 'Q52WX2',\n",
       " 'Q9NZ71',\n",
       " 'Q13761',\n",
       " 'Q9Y230',\n",
       " 'P34925',\n",
       " 'O76082',\n",
       " 'O14975',\n",
       " 'Q9Y2P5',\n",
       " 'Q9UBT2',\n",
       " 'P0C264',\n",
       " 'Q9H015',\n",
       " 'Q13950',\n",
       " 'Q9Y265',\n",
       " 'Q9Y3I0',\n",
       " 'Q96KG9',\n",
       " 'P0C263',\n",
       " 'O00442',\n",
       " 'Q01196',\n",
       " 'O00141',\n",
       " 'Q9UQD0',\n",
       " 'Q6P3W7',\n",
       " 'P21675',\n",
       " 'P17987',\n",
       " 'Q9H2K8',\n",
       " 'Q03519',\n",
       " 'P78371',\n",
       " 'P42680',\n",
       " 'A2RTX5',\n",
       " 'P23381',\n",
       " 'P54577',\n",
       " 'Q96SF2',\n",
       " 'Q15569',\n",
       " 'P26639',\n",
       " 'Q9BW92',\n",
       " 'Q9Y2Z4',\n",
       " 'Q8TEA7',\n",
       " 'O43776',\n",
       " 'P26640',\n",
       " 'Q9UL54',\n",
       " 'Q7L3T8',\n",
       " 'P47897',\n",
       " 'P13984',\n",
       " 'P50990',\n",
       " 'Q9UHD2',\n",
       " 'P50991',\n",
       " 'P48643',\n",
       " 'A6NM43',\n",
       " 'Q92526',\n",
       " 'P40227',\n",
       " 'Q99973',\n",
       " 'Q03518',\n",
       " 'Q587J7',\n",
       " 'P55072',\n",
       " 'Q9H497',\n",
       " 'Q02763',\n",
       " 'Q12931',\n",
       " 'O43615',\n",
       " 'Q9UKE5',\n",
       " 'Q9ULW0',\n",
       " 'Q86UE8',\n",
       " 'O14657',\n",
       " 'Q02880',\n",
       " 'Q9H3S4',\n",
       " 'O75962',\n",
       " 'Q96KB5',\n",
       " 'O14656',\n",
       " 'Q9Y2W1',\n",
       " 'Q5JU69',\n",
       " 'P11388',\n",
       " 'Q96Q11',\n",
       " 'Q96QT4',\n",
       " 'Q96PN8',\n",
       " 'Q6IQ55',\n",
       " 'O95922',\n",
       " 'P42681',\n",
       " 'A1L167',\n",
       " 'Q9NXH8',\n",
       " 'Q96PF2',\n",
       " 'Q8TD43',\n",
       " 'Q9BX84',\n",
       " 'Q8NER1',\n",
       " 'Q9BXA6',\n",
       " 'Q96RU7',\n",
       " 'Q9HBA0',\n",
       " 'Q3LXA3',\n",
       " 'Q13470',\n",
       " 'Q8N2E6',\n",
       " 'Q9BXA7',\n",
       " 'Q5TCY1',\n",
       " 'Q9Y4R7',\n",
       " 'A6PVC2',\n",
       " 'Q8NG68',\n",
       " 'P62253',\n",
       " 'Q9Y385',\n",
       " 'P49459',\n",
       " 'O00762',\n",
       " 'Q9H832',\n",
       " 'Q6SA08',\n",
       " 'Q9UNY4',\n",
       " 'P33981',\n",
       " 'Q6IBS0',\n",
       " 'O75643',\n",
       " 'Q9Y2X8',\n",
       " 'P51965',\n",
       " 'Q8N2K1',\n",
       " 'Q7Z7E8',\n",
       " 'Q712K3',\n",
       " 'Q9GZZ9',\n",
       " 'Q9NPD8',\n",
       " 'Q6ZT98',\n",
       " 'Q3SXZ7',\n",
       " 'Q96LR5',\n",
       " 'Q8WVN8',\n",
       " 'P49427',\n",
       " 'Q8TBC4',\n",
       " 'P63146',\n",
       " 'Q9C0C9',\n",
       " 'Q96B02',\n",
       " 'P62837',\n",
       " 'P61077',\n",
       " 'Q969M7',\n",
       " 'O95155',\n",
       " 'A0AVT1',\n",
       " 'Q9HA47',\n",
       " 'P29597',\n",
       " 'P51668',\n",
       " 'Q969T4',\n",
       " 'P68036',\n",
       " 'P61081',\n",
       " 'P63279',\n",
       " 'Q9NWZ5',\n",
       " 'Q8NHH1',\n",
       " 'Q9BWV7',\n",
       " 'Q14679',\n",
       " 'P22314',\n",
       " 'P62256',\n",
       " 'P61086',\n",
       " 'P61088',\n",
       " 'Q16763',\n",
       " 'Q5VVX9',\n",
       " 'Q9BZX2',\n",
       " 'P30530',\n",
       " 'O75385',\n",
       " 'Q96C45',\n",
       " 'A6NNM8',\n",
       " 'Q6EMB2',\n",
       " 'Q8N841',\n",
       " 'Q12792',\n",
       " 'Q06418',\n",
       " 'P60604',\n",
       " 'P41226',\n",
       " 'P21281',\n",
       " 'O43314',\n",
       " 'Q8IYT8',\n",
       " 'Q6ZVT0',\n",
       " 'Q14166',\n",
       " 'Q8TAS1',\n",
       " 'Q6PHR2',\n",
       " 'Q6PFW1',\n",
       " 'P15313',\n",
       " 'P35916',\n",
       " 'Q96J92',\n",
       " 'Q96S55',\n",
       " 'Q15904',\n",
       " 'A3KMH1',\n",
       " 'P17948',\n",
       " 'P35968',\n",
       " 'Q9Y4B6',\n",
       " 'P30291',\n",
       " 'P0C1S8',\n",
       " 'P38606',\n",
       " 'Q96TA2',\n",
       " 'Q5FWF4',\n",
       " 'Q9UGI9',\n",
       " 'P54646',\n",
       " 'Q96GR2',\n",
       " 'P42684',\n",
       " 'Q08AH3',\n",
       " 'P54619',\n",
       " 'Q4W5N1',\n",
       " 'Q86UK0',\n",
       " 'Q9NUT2',\n",
       " 'Q9NRK6',\n",
       " 'Q9NSE7',\n",
       " 'P33897',\n",
       " 'P28288',\n",
       " 'Q9H222',\n",
       " 'O95477',\n",
       " 'Q8WWZ7',\n",
       " 'Q8IUA7',\n",
       " 'Q86UQ4',\n",
       " 'O75027',\n",
       " 'Q9NP78',\n",
       " 'O95342',\n",
       " 'Q13085',\n",
       " 'P53396',\n",
       " 'P33121',\n",
       " 'Q9ULC5',\n",
       " 'Q13131',\n",
       " 'Q8N139',\n",
       " 'Q9H221',\n",
       " 'Q09428',\n",
       " 'Q96J66',\n",
       " 'Q9UBJ2',\n",
       " 'Q9UNQ0',\n",
       " 'Q8IZY2',\n",
       " 'Q2M3G0',\n",
       " 'Q9NP58',\n",
       " 'Q9BZC7',\n",
       " 'Q99758',\n",
       " 'P78363',\n",
       " 'O94911',\n",
       " 'Q8WWZ4',\n",
       " 'O60706',\n",
       " 'O14678',\n",
       " 'Q9UG63',\n",
       " 'P00519',\n",
       " 'Q2M2I8',\n",
       " 'P61221',\n",
       " 'Q8NE71',\n",
       " 'Q9NUQ8',\n",
       " 'P45844',\n",
       " 'Q9H172',\n",
       " 'Q86TW2',\n",
       " 'P51828',\n",
       " 'Q53H12',\n",
       " 'P31749',\n",
       " 'Q4L235',\n",
       " 'P68032',\n",
       " 'Q08462',\n",
       " 'P60709',\n",
       " 'P63261',\n",
       " 'P37023',\n",
       " 'Q8NFM4',\n",
       " 'O43306',\n",
       " 'Q4G176',\n",
       " 'Q04771',\n",
       " 'Q68CK6',\n",
       " 'Q9NR19',\n",
       " 'Q96CM8',\n",
       " 'Q562R1',\n",
       " 'P61163',\n",
       " 'Q07912',\n",
       " 'Q7Z695',\n",
       " 'Q9Y4W6',\n",
       " 'Q5FVE4',\n",
       " 'P42025',\n",
       " 'Q8WYK0',\n",
       " 'Q6P461',\n",
       " 'P62736',\n",
       " 'P68133',\n",
       " 'O60266',\n",
       " 'P40145',\n",
       " 'Q86V21',\n",
       " 'Q9UGJ0',\n",
       " 'Q9BTE6',\n",
       " 'O00763',\n",
       " 'Q08AH1',\n",
       " 'Q53FZ2',\n",
       " 'P0C7M7',\n",
       " 'Q8NER5',\n",
       " 'O95573',\n",
       " 'O60488',\n",
       " 'Q9UKU0',\n",
       " 'Q6NUN0',\n",
       " 'Q9H6R3',\n",
       " 'Q9BYX7',\n",
       " 'P63267',\n",
       " 'P36896',\n",
       " 'Q96PN6',\n",
       " 'P31751',\n",
       " 'Q86TB3',\n",
       " 'Q96QP1',\n",
       " 'Q9Y243',\n",
       " 'Q08828',\n",
       " 'Q9NUB1',\n",
       " 'O95622',\n",
       " 'Q9UM73',\n",
       " 'O60503',\n",
       " 'Q16671',\n",
       " 'P16066',\n",
       " 'P20594',\n",
       " 'O14727',\n",
       " 'P10398',\n",
       " 'P25098',\n",
       " 'P55263',\n",
       " 'Q96L96',\n",
       " 'Q8NFD2',\n",
       " 'Q9Y4B4',\n",
       " 'P13637',\n",
       " 'Q16720',\n",
       " 'Q5T9A4',\n",
       " 'Q8NB49',\n",
       " 'P05023',\n",
       " 'Q13733',\n",
       " 'Q9ULI0',\n",
       " 'P00966',\n",
       " 'Q9P1U1',\n",
       " 'P61158',\n",
       " 'P35626',\n",
       " 'P61160',\n",
       " 'Q9Y2Q0',\n",
       " 'O43520',\n",
       " 'O60423',\n",
       " 'Q96QE3',\n",
       " 'O43681',\n",
       " 'O60312',\n",
       " 'P98196',\n",
       " 'P54707',\n",
       " 'Q4VNC0',\n",
       " 'P50993',\n",
       " 'O14983',\n",
       " 'P06576',\n",
       " 'Q9C0K3',\n",
       " 'Q9P241',\n",
       " 'Q9Y2G3',\n",
       " 'Q9NQ11',\n",
       " 'Q13315',\n",
       " 'P20020',\n",
       " 'Q01814',\n",
       " 'P23634',\n",
       " 'P98194',\n",
       " 'Q9NVI7',\n",
       " 'Q9UQB9',\n",
       " 'Q8TF62',\n",
       " 'Q04656',\n",
       " 'P35670',\n",
       " 'Q9H981',\n",
       " 'Q9HD20',\n",
       " 'Q5T2N8',\n",
       " 'P20648',\n",
       " 'O75110',\n",
       " 'Q8N3C0',\n",
       " 'Q8NBU5',\n",
       " 'Q6PL18',\n",
       " 'P08243',\n",
       " 'O94823',\n",
       " 'Q9H7F0',\n",
       " 'Q4VNC1',\n",
       " 'P16615',\n",
       " 'Q93084',\n",
       " 'O75185',\n",
       " 'Q9NTI2',\n",
       " 'P25705',\n",
       " 'Q9UIG0',\n",
       " 'Q96GD4',\n",
       " 'Q6ZW61',\n",
       " 'P27037',\n",
       " 'P98198',\n",
       " 'O43861',\n",
       " 'O14965',\n",
       " 'O14874',\n",
       " 'P46100',\n",
       " 'Q13873',\n",
       " 'Q13705',\n",
       " 'Q8TAM1',\n",
       " 'P51451',\n",
       " 'Q14692',\n",
       " 'Q8IWQ3',\n",
       " 'O60566',\n",
       " 'Q13075',\n",
       " 'O00238',\n",
       " 'Q9Y276',\n",
       " 'Q13535',\n",
       " 'P11274',\n",
       " 'P54132',\n",
       " 'P15056',\n",
       " 'P11586',\n",
       " 'Q8NCB2',\n",
       " 'P51813',\n",
       " 'Q6UB35',\n",
       " 'Q9BRT8',\n",
       " 'Q4V339',\n",
       " 'Q9NSY1',\n",
       " 'P36894',\n",
       " 'P50747',\n",
       " 'Q00975',\n",
       " 'O43683',\n",
       " 'P33076',\n",
       " 'Q06187',\n",
       " 'Q8TDC3',\n",
       " 'O14981',\n",
       " 'Q00526',\n",
       " 'Q8IUF1',\n",
       " 'A6NM15',\n",
       " 'Q96Q40',\n",
       " 'Q9UQ88',\n",
       " 'Q8IVW4',\n",
       " 'Q5MAI5',\n",
       " 'Q8N884',\n",
       " 'Q9BWU1',\n",
       " 'Q00534',\n",
       " 'Q00532',\n",
       " 'Q8TCT0',\n",
       " 'P21127',\n",
       " 'P49336',\n",
       " 'P50750',\n",
       " 'Q92772',\n",
       " 'O76039',\n",
       " 'Q5RIA9',\n",
       " 'Q99741',\n",
       " 'O00311',\n",
       " 'O94921',\n",
       " 'Q07002',\n",
       " 'P24941',\n",
       " 'O14578',\n",
       " 'P19784',\n",
       " 'P49916',\n",
       " 'P49917',\n",
       " 'Q8IVF4',\n",
       " 'Q0VDD8',\n",
       " 'Q8WW22',\n",
       " 'Q96EY1',\n",
       " 'Q8TE96',\n",
       " 'O60884',\n",
       " 'P18858',\n",
       " 'O60231',\n",
       " 'Q7L2E3',\n",
       " 'Q7L7V1',\n",
       " 'Q14147',\n",
       " 'Q6P158',\n",
       " 'P51530',\n",
       " 'Q7L8W6',\n",
       " 'Q5JTY5',\n",
       " 'Q15131',\n",
       " 'Q9NYV4',\n",
       " 'Q14004',\n",
       " 'Q00536',\n",
       " 'P50613',\n",
       " 'Q02224',\n",
       " 'Q12873',\n",
       " 'Q8TD26',\n",
       " 'Q9UHD1',\n",
       " 'Q00535',\n",
       " 'O14757',\n",
       " 'Q00537',\n",
       " 'P06493',\n",
       " 'P11802',\n",
       " 'P13569',\n",
       " 'P61604',\n",
       " 'P10809',\n",
       " 'O96017',\n",
       " 'P51790',\n",
       " 'Q8IZL9',\n",
       " 'Q92989',\n",
       " 'Q5EBM0',\n",
       " 'Q14839',\n",
       " 'Q9HCK8',\n",
       " 'P51793',\n",
       " 'P51795',\n",
       " 'O14646',\n",
       " 'Q8TDI0',\n",
       " 'P35790',\n",
       " 'Q9Y259',\n",
       " 'P51797',\n",
       " 'P49760',\n",
       " 'Q86WJ1',\n",
       " 'O14647',\n",
       " 'Q9P2D1',\n",
       " 'Q3L8U1',\n",
       " 'Q9H078',\n",
       " 'P51798',\n",
       " 'P49759',\n",
       " 'Q9HAZ1',\n",
       " 'Q9H8M5',\n",
       " 'O76031',\n",
       " 'Q8NEV1',\n",
       " 'P68400',\n",
       " 'O14936',\n",
       " 'Q96D53',\n",
       " 'Q8NI60',\n",
       " 'P31327',\n",
       " 'P41240',\n",
       " 'Q13057',\n",
       " 'A5YM72',\n",
       " 'P49761',\n",
       " 'O43293',\n",
       " 'P07333',\n",
       " 'Q8IWT3',\n",
       " 'Q8WVB6',\n",
       " 'A8MPP1',\n",
       " 'Q9Y6G9',\n",
       " 'Q8WVC6',\n",
       " 'P53355',\n",
       " 'O43237',\n",
       " 'P26196',\n",
       " 'O15075',\n",
       " 'Q9NUU7',\n",
       " 'Q9NR30',\n",
       " 'Q7L014',\n",
       " 'Q9BQ39',\n",
       " 'Q86TM3',\n",
       " 'P17844',\n",
       " 'P23743',\n",
       " 'Q16760',\n",
       " 'P49619',\n",
       " 'P52824',\n",
       " 'Q8IX18',\n",
       " 'Q14562',\n",
       " 'Q13206',\n",
       " 'Q92841',\n",
       " 'Q92499',\n",
       " 'Q96GQ7',\n",
       " 'Q86XP3',\n",
       " 'Q9Y6T7',\n",
       " 'P52429',\n",
       " 'Q9H2U1',\n",
       " 'Q08211',\n",
       " 'Q09013',\n",
       " 'Q16832',\n",
       " 'Q92771',\n",
       " 'Q9NVP1',\n",
       " 'Q9H8H2',\n",
       " 'O15523',\n",
       " 'Q9UJV9',\n",
       " 'Q9Y6V7',\n",
       " 'Q9NQI0',\n",
       " 'Q9NY93',\n",
       " 'O95786',\n",
       " 'Q5KSL6',\n",
       " 'Q13574',\n",
       " 'Q9UPY3',\n",
       " 'Q14565',\n",
       " 'Q9UMR2',\n",
       " 'Q08345',\n",
       " 'Q9GZR7',\n",
       " 'Q9UHL0',\n",
       " 'Q9NXZ2',\n",
       " 'Q8NHQ9',\n",
       " 'Q8IY21',\n",
       " 'P27707',\n",
       " 'Q9C098',\n",
       " 'Q9UHI6',\n",
       " 'Q5H9U9',\n",
       " 'O75912',\n",
       " 'O43143',\n",
       " 'Q7Z478',\n",
       " 'Q9H6R0',\n",
       " 'Q96C10',\n",
       " 'Q9H0S4',\n",
       " 'Q16854',\n",
       " 'P00367',\n",
       " 'Q5D0E6',\n",
       " 'Q8N568',\n",
       " 'Q9BUQ8',\n",
       " 'Q9Y2R4',\n",
       " 'Q96FC9',\n",
       " 'Q9NUL7',\n",
       " 'O00571',\n",
       " 'Q8N8A6',\n",
       " 'Q8TDD1',\n",
       " 'Q5T1V6',\n",
       " 'Q86XP1',\n",
       " 'Q9UIK4',\n",
       " 'Q9H5Z1',\n",
       " 'Q8IY37',\n",
       " 'P31689',\n",
       " 'O00148',\n",
       " 'Q13627',\n",
       " 'Q9NR20',\n",
       " 'Q6XUX3',\n",
       " 'Q8TD57',\n",
       " 'Q9C0G6',\n",
       " 'P00533',\n",
       " 'O75417',\n",
       " 'Q96DT5',\n",
       " 'Q96JB1',\n",
       " 'Q9NYC9',\n",
       " 'Q9NZJ5',\n",
       " 'Q92630',\n",
       " 'P49770',\n",
       " 'Q9UFH2',\n",
       " 'Q9P2D7',\n",
       " 'Q8TE73',\n",
       " 'Q8WXX0',\n",
       " 'Q14204',\n",
       " 'Q8NCM8',\n",
       " 'O43781',\n",
       " 'Q9P2K8',\n",
       " 'Q6ZR08',\n",
       " 'Q9P225',\n",
       " 'Q9Y463',\n",
       " 'P49961',\n",
       " 'Q5MY95',\n",
       " 'P54764',\n",
       " 'P29322',\n",
       " 'P54762',\n",
       " 'O15197',\n",
       " 'Q58FF3',\n",
       " 'P22413',\n",
       " 'P21860',\n",
       " 'Q15303',\n",
       " 'P18074',\n",
       " 'Q9NZN3',\n",
       " 'Q96L91',\n",
       " 'Q76MJ5',\n",
       " 'P19525',\n",
       " 'Q9H4M9',\n",
       " 'Q9NZN4',\n",
       " 'Q9H223',\n",
       " 'Q13838',\n",
       " 'Q9BQI3',\n",
       " 'P29317',\n",
       " 'Q5T890',\n",
       " 'O00418',\n",
       " 'Q9HBU6',\n",
       " 'Q9UF33',\n",
       " 'P54753',\n",
       " 'P04626',\n",
       " 'Q2NKX8',\n",
       " 'Q16877',\n",
       " 'Q9NVF9',\n",
       " 'P14625',\n",
       " 'Q9Y5L3',\n",
       " 'P16452',\n",
       " 'Q5JZY3',\n",
       " 'P29323',\n",
       " 'Q03468',\n",
       " 'O75355',\n",
       " 'Q15375',\n",
       " 'O75460',\n",
       " 'P21709',\n",
       " 'P29320',\n",
       " 'P54756',\n",
       " 'P54760',\n",
       " 'P16118',\n",
       " 'Q8IXL6',\n",
       " 'Q6ZS86',\n",
       " 'Q14410',\n",
       " 'Q14409',\n",
       " 'P48637',\n",
       " 'P11021',\n",
       " 'Q8NFF5',\n",
       " 'Q05397',\n",
       " 'Q9BX63',\n",
       " 'P09769',\n",
       " 'A6NMB9',\n",
       " 'P22455',\n",
       " 'Q8NFZ0',\n",
       " 'P11362',\n",
       " 'Q5HY92',\n",
       " 'P19447',\n",
       " 'O60825',\n",
       " 'P16591',\n",
       " 'P22607',\n",
       " 'Q16875',\n",
       " 'Q14296',\n",
       " 'Q14289',\n",
       " 'Q8IYD8',\n",
       " 'Q9BRP7',\n",
       " 'P07332',\n",
       " 'Q02790',\n",
       " 'P42685',\n",
       " 'Q6PIW4',\n",
       " 'P06241',\n",
       " 'Q9Y2I7',\n",
       " 'Q05932',\n",
       " 'P21802',\n",
       " 'Q9BVA6',\n",
       " 'P36888',\n",
       " 'O43716',\n",
       " 'Q8N0W3',\n",
       " 'Q9H0R6',\n",
       " 'Q01415',\n",
       " 'P51570',\n",
       " 'Q13283',\n",
       " 'Q5T6J7',\n",
       " 'Q8IVS8',\n",
       " 'Q6PIY7',\n",
       " 'P32189',\n",
       " 'O14976',\n",
       " 'Q9NQX3',\n",
       " 'Q9Y223',\n",
       " 'P15104',\n",
       " 'O75879',\n",
       " 'P49915',\n",
       " 'Q75WM6',\n",
       " 'P32298',\n",
       " 'P49840',\n",
       " 'Q8WTQ7',\n",
       " 'P38646',\n",
       " 'P51841',\n",
       " 'Q58FF6',\n",
       " 'P43250',\n",
       " 'P34947',\n",
       " 'P49841',\n",
       " 'P25092',\n",
       " 'Q58FF8',\n",
       " 'P48506',\n",
       " 'Q96GX5',\n",
       " 'Q8TDG4',\n",
       " 'Q02846',\n",
       " 'Q8TF76',\n",
       " 'Q58FF7',\n",
       " 'P08631',\n",
       " 'Q8NG08',\n",
       " 'Q9BYK8',\n",
       " 'Q9NRZ9',\n",
       " 'P42694',\n",
       " 'Q9H422',\n",
       " 'Q14527',\n",
       " 'A2PYH4',\n",
       " 'Q8NE63',\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "has_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5cf8124d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_size = 500 #only 500 chain lenth is considered\n",
    "\n",
    "X = []          \n",
    "y = []  \n",
    "\n",
    "pos_examples = 0\n",
    "neg_examples = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c36603c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P27361,MAAAAAQGGGGGEPRRTEGVGPGVPGEVEMVKGQPFDVGPRYTQLQYIGEGAYGMVSSAYDHVRKTRVAIKKISPFEHQTYCQRTLREIQILLRFRHENVIGIRDILRASTLEAMRDVYIVQDLMETDLYKLLKSQQLSNDHICYFLYQILRGLKYIHSANVLHRDLKPSNLLINTTCDLKICDFGLARIADPEHDHTGFLTEYVATRWYRAPEIMLNSKGYTKSIDIWSVGCILAEMLSNRPIFPGKHYLDQLNHILGILGSPSQEDLNCIINMKARNYLQSLPSKTKVAWAKLFPKSDSKALDLLDRMLTFNPNKRITVEEALAHPYLEQYYDPTDEPVAEEPFTFAMELDDLPKERLKELIFQETARFQPGVLEAP\n",
      "\n",
      "P53779,MSLHFLYYCSEPTLDVKIAFCQGFDKQVDVSYIAKHYNMSKSKVDNQFYSVEVGDSTFTVLKRYQNLKPIGSGAQGIVCAAYDAVLDRNVAIKKLSRPFQNQTHAKRAYRELVLMKCVNHKNIISLLNVFTPQKTLEEFQDVYLVMELMDANLCQVIQMELDHERMSYLLYQMLCGIKHLHSAGIIHRDLKPSNIVVKSDCTLKILDFGLARTAGTSFMMTPYVVTRYYRAPEVILGMGYKENVDIWSVGCIMGEMVRHKILFPGRDYIDQWNKVIEQLGTPCPEFMKKLQPTVRNYVENRPKYAGLTFPKLFPDSLFPADSEHNKLKASQARDLLSKMLVIDPAKRISVDDALQHPYINVWYDPAEVEAPPPQIYDKQLDEREHTIEEWKELIYKEVMNSEEKTKNGVVKGQPSPSGAAVNSSESLPPSSSVNDISSMSTDQTLASDTDSSLEASAGPLGCCR\n",
      "\n",
      "Q15049,MTQEPFREELAYDRMPTLERGRQDPASYAPDAKPSDLQLSKRLPPCFSHKTWVFSVLMGSCLLVTSGFSLYLGNVFPAEMDYLRCAAGSCIPSAIVSFTVSRRNANVIPNFQILFVSTFAVTTTCLIWFGCKLVLNPSAININFNLILLLLLELLMAATVIIAARSSEEDCKKKKGSMSDSANILDEVPFPARVLKSYSVVEVIAGISAVLGGIIALNVDDSVSGPHLSVTFFWILVACFPSAIASHVAAECPSKCLVEVLIAISSLTSPLLFTASGYLSFSIMRIVEMFKDYPPAIKPSYDVLLLLLLLVLLLQAGLNTGTAIQCVRFKVSARLQGASWDTQNGPQERLAGEVARSPLKEFDKEKAWRAVVVQMAQ\n",
      "\n",
      "P0DMT0,MTGKNWILISTTTPKSLEDEIVGRLLKILFVIFVDLISIIYVVITS\n",
      "\n",
      "Q7L9L4,MSFLFGSRSSKTFKPKKNIPEGSHQYELLKHAEATLGSGNLRMAVMLPEGEDLNEWVAVNTVDFFNQINMLYGTITDFCTEESCPVMSAGPKYEYHWADGTNIKKPIKCSAPKYIDYLMTWVQDQLDDETLFPSKIGVPFPKNFMSVAKTILKRLFRVYAHIYHQHFDPVIQLQEEAHLNTSFKHFIFFVQEFNLIDRRELAPLQELIEKLTSKDR\n",
      "\n",
      "Q86TA1,MSIALKQVFNKDKTFRPKRKFEPGTQRFELHKRAQASLNSGVDLKAAVQLPSGEDQNDWVAVHVVDFFNRINLIYGTICEFCTERTCPVMSGGPKYEYRWQDDLKYKKPTALPAPQYMNLLMDWIEVQINNEEIFPTCVGVPFPKNFLQICKKILCRLFRVFVHVYIHHFDRVIVMGAEAHVNTCYKHFYYFVTEMNLIDRKELEPLKEMTSRMCH\n",
      "\n",
      "Q86TA1,MSIALKQVFNKDKTFRPKRKFEPGTQRFELHKRAQASLNSGVDLKAAVQLPSGEDQNDWVAVHVVDFFNRINLIYGTICEFCTERTCPVMSGGPKYEYRWQDDLKYKKPTALPAPQYMNLLMDWIEVQINNEEIFPTCVGVPFPKNFLQICKKILCRLFRVFVHVYIHHFDRVIVMGAEAHVNTCYKHFYYFVTEMNLIDRKELEPLKEMTSRMCH\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(sequences_file) as f:\n",
    "    for line in f:\n",
    "        ln = line.split(',')\n",
    "        protein_id = ln[0].strip()\n",
    "        seq = ln[1].strip()\n",
    "\n",
    "        # we're doing this to reduce input size\n",
    "        if len(seq) >= max_sequence_size:\n",
    "            continue\n",
    "        \n",
    "        print(line)\n",
    "        \n",
    "        X.append(seq)\n",
    "        \n",
    "        if protein_id in has_function: \n",
    "            y.append(1) \n",
    "            pos_examples += 1 \n",
    "        else: \n",
    "            y.append(0) \n",
    "            neg_examples += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d763af11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Examples: 2\n",
      "Negative Examples: 5\n"
     ]
    }
   ],
   "source": [
    "print(\"Positive Examples: %d\" % pos_examples)\n",
    "print(\"Negative Examples: %d\" % neg_examples) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa26e49",
   "metadata": {},
   "source": [
    "## Convert amino acid letters to indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95309e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_to_indices(sequence):\n",
    "    \"\"\"Convert amino acid letters to indices. \n",
    "       _ means no amino acid (used for padding to accommodate for variable length)\"\"\"\n",
    "    \n",
    "    try:\n",
    "        acid_letters = ['_', 'A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M',\n",
    "                'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y']\n",
    "\n",
    "        indices = [acid_letters.index(c) for c in list(sequence)]\n",
    "        return indices\n",
    "    except Exception:\n",
    "        print(sequence)\n",
    "        raise Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94bee592",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = [] \n",
    "for i in range(len(X)): \n",
    "    x = sequence_to_indices(X[i])\n",
    "    X_all.append(x) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3bf0d5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RG\\AppData\\Local\\Temp\\ipykernel_12088\\467407808.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_all = np.array(X_all)\n"
     ]
    }
   ],
   "source": [
    "X_all = np.array(X_all)\n",
    "y_all = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11d40fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[11, 1, 1, 1, 1, 1, 14, 6, 6, 6, 6, 6, 4, 13, 15, 15, 17, 4, 6, 19, 6, 13, 6, 19, 13, 6, 4, 19, 4, 11, 19, 9, 6, 14, 13, 5, 3, 19, 6, 13, 15, 22, 17, 14, 10, 14, 22, 8, 6, 4, 6, 1, 22, 6, 11, 19, 16, 16, 1, 22, 3, 7, 19, 15, 9, 17, 15, 19, 1, 8, 9, 9, 8, 16, 13, 5, 4, 7, 14, 17, 22, 2, 14, 15, 17, 10, 15, 4, 8, 14, 8, 10, 10, 15, 5, 15, 7, 4, 12, 19, 8, 6, 8, 15, 3, 8, 10, 15, 1, 16, 17, 10, 4, 1, 11, 15, 3, 19, 22, 8, 19, 14, 3, 10, 11, 4, 17, 3, 10, 22, 9, 10, 10, 9, 16, 14, 14, 10, 16, 12, 3, 7, 8, 2, 22, 5, 10, 22, 14, 8, 10, 15, 6, 10, 9, 22, 8, 7, 16, 1, 12, 19, 10, 7, 15, 3, 10, 9, 13, 16, 12, 10, 10, 8, 12, 17, 17, 2, 3, 10, 9, 8, 2, 3, 5, 6, 10, 1, 15, 8, 1, 3, 13, 4, 7, 3, 7, 17, 6, 5, 10, 17, 4, 22, 19, 1, 17, 15, 20, 22, 15, 1, 13, 4, 8, 11, 10, 12, 16, 9, 6, 22, 17, 9, 16, 8, 3, 8, 20, 16, 19, 6, 2, 8, 10, 1, 4, 11, 10, 16, 12, 15, 13, 8, 5, 13, 6, 9, 7, 22, 10, 3, 14, 10, 12, 7, 8, 10, 6, 8, 10, 6, 16, 13, 16, 14, 4, 3, 10, 12, 2, 8, 8, 12, 11, 9, 1, 15, 12, 22, 10, 14, 16, 10, 13, 16, 9, 17, 9, 19, 1, 20, 1, 9, 10, 5, 13, 9, 16, 3, 16, 9, 1, 10, 3, 10, 10, 3, 15, 11, 10, 17, 5, 12, 13, 12, 9, 15, 8, 17, 19, 4, 4, 1, 10, 1, 7, 13, 22, 10, 4, 14, 22, 22, 3, 13, 17, 3, 4, 13, 19, 1, 4, 4, 13, 5, 17, 5, 1, 11, 4, 10, 3, 3, 10, 13, 9, 4, 15, 10, 9, 4, 10, 8, 5, 14, 4, 17, 1, 15, 5, 14, 13, 6, 19, 10, 4, 1, 13]\n",
      "379\n"
     ]
    }
   ],
   "source": [
    "## testing the if things look alright\n",
    "print(y[0])\n",
    "print(X_all[0])\n",
    "print(len(X_all[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "285c7162",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = sequence.pad_sequences(X_all, maxlen = max_sequence_size)  # to overcome the variable length issue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f3f4ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0, 11,  1,  1,  1,  1,  1, 14,  6,  6,  6,  6,  6,  4, 13, 15,\n",
       "       15, 17,  4,  6, 19,  6, 13,  6, 19, 13,  6,  4, 19,  4, 11, 19,  9,\n",
       "        6, 14, 13,  5,  3, 19,  6, 13, 15, 22, 17, 14, 10, 14, 22,  8,  6,\n",
       "        4,  6,  1, 22,  6, 11, 19, 16, 16,  1, 22,  3,  7, 19, 15,  9, 17,\n",
       "       15, 19,  1,  8,  9,  9,  8, 16, 13,  5,  4,  7, 14, 17, 22,  2, 14,\n",
       "       15, 17, 10, 15,  4,  8, 14,  8, 10, 10, 15,  5, 15,  7,  4, 12, 19,\n",
       "        8,  6,  8, 15,  3,  8, 10, 15,  1, 16, 17, 10,  4,  1, 11, 15,  3,\n",
       "       19, 22,  8, 19, 14,  3, 10, 11,  4, 17,  3, 10, 22,  9, 10, 10,  9,\n",
       "       16, 14, 14, 10, 16, 12,  3,  7,  8,  2, 22,  5, 10, 22, 14,  8, 10,\n",
       "       15,  6, 10,  9, 22,  8,  7, 16,  1, 12, 19, 10,  7, 15,  3, 10,  9,\n",
       "       13, 16, 12, 10, 10,  8, 12, 17, 17,  2,  3, 10,  9,  8,  2,  3,  5,\n",
       "        6, 10,  1, 15,  8,  1,  3, 13,  4,  7,  3,  7, 17,  6,  5, 10, 17,\n",
       "        4, 22, 19,  1, 17, 15, 20, 22, 15,  1, 13,  4,  8, 11, 10, 12, 16,\n",
       "        9,  6, 22, 17,  9, 16,  8,  3,  8, 20, 16, 19,  6,  2,  8, 10,  1,\n",
       "        4, 11, 10, 16, 12, 15, 13,  8,  5, 13,  6,  9,  7, 22, 10,  3, 14,\n",
       "       10, 12,  7,  8, 10,  6,  8, 10,  6, 16, 13, 16, 14,  4,  3, 10, 12,\n",
       "        2,  8,  8, 12, 11,  9,  1, 15, 12, 22, 10, 14, 16, 10, 13, 16,  9,\n",
       "       17,  9, 19,  1, 20,  1,  9, 10,  5, 13,  9, 16,  3, 16,  9,  1, 10,\n",
       "        3, 10, 10,  3, 15, 11, 10, 17,  5, 12, 13, 12,  9, 15,  8, 17, 19,\n",
       "        4,  4,  1, 10,  1,  7, 13, 22, 10,  4, 14, 22, 22,  3, 13, 17,  3,\n",
       "        4, 13, 19,  1,  4,  4, 13,  5, 17,  5,  1, 11,  4, 10,  3,  3, 10,\n",
       "       13,  9,  4, 15, 10,  9,  4, 10,  8,  5, 14,  4, 17,  1, 15,  5, 14,\n",
       "       13,  6, 19, 10,  4,  1, 13])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc32a32",
   "metadata": {},
   "source": [
    "# Now Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e2b4f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 500)\n",
      "(7,)\n"
     ]
    }
   ],
   "source": [
    "print(X_all.shape)  \n",
    "print(y_all.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61eeeee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = X_all.shape[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d594c35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "randomize = np.arange(n)\n",
    "np.random.shuffle(randomize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "54fc968e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = X_all[randomize]\n",
    "y_all = y_all[randomize]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dd9f3b",
   "metadata": {},
   "source": [
    "## Splitting in 66.66 and 33.33 ~(70-30 ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "338b49c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split = round(n * 2 / 3) ## splitting in 66.66 and 33.33\n",
    "X_train = X_all[:test_split]   \n",
    "y_train = y_all[:test_split]   \n",
    "X_test  = X_all[test_split:]   \n",
    "y_test  = y_all[test_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3de91a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 500)\n",
      "(5,)\n",
      "(2, 500)\n",
      "(2,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faad56e7",
   "metadata": {},
   "source": [
    "## Applying Artifical Neural Network (ANN) to classify the protein function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "70b18b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, Input, Dropout, Flatten, Dense, Activation\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf0f3fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e604cd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#round-1 with 10 epoches - 60% accuracy\n",
    "#round-2 with 100 epoches\n",
    "num_amino_acids = 23 \n",
    "embedding_dims = 10 \n",
    "nb_epoch = 100  #round-1 with 10 epoches\n",
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5ca22505",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() \n",
    "\n",
    "model.add(Embedding(num_amino_acids, embedding_dims, input_length=max_sequence_size  ))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(25, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "409b3764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 500, 10)           230       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 5000)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 25)                125025    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 125,281\n",
      "Trainable params: 125,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "687afb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=SGD(),     #Stochastic Gradient Descent\n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e6f3a94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 500, 10)           230       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 5000)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 25)                125025    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 125,281\n",
      "Trainable params: 125,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "96e6081b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 0.6723 - accuracy: 0.6000 - val_loss: 0.4561 - val_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.6741 - accuracy: 0.6000 - val_loss: 0.4672 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.6719 - accuracy: 0.6000 - val_loss: 0.4778 - val_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.6669 - accuracy: 0.6000 - val_loss: 0.4730 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.6658 - accuracy: 0.6000 - val_loss: 0.4686 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6646 - accuracy: 0.6000 - val_loss: 0.4644 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.6635 - accuracy: 0.6000 - val_loss: 0.4604 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.6651 - accuracy: 0.6000 - val_loss: 0.4708 - val_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.6600 - accuracy: 0.6000 - val_loss: 0.4664 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.6588 - accuracy: 0.6000 - val_loss: 0.4622 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.6575 - accuracy: 0.6000 - val_loss: 0.4582 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.6590 - accuracy: 0.6000 - val_loss: 0.4686 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.6567 - accuracy: 0.6000 - val_loss: 0.4788 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.6516 - accuracy: 0.6000 - val_loss: 0.4737 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.6530 - accuracy: 0.6000 - val_loss: 0.4836 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6553 - accuracy: 0.6000 - val_loss: 0.4783 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.6463 - accuracy: 0.6000 - val_loss: 0.4729 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.6521 - accuracy: 0.6000 - val_loss: 0.4680 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6460 - accuracy: 0.6000 - val_loss: 0.4780 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.6435 - accuracy: 0.6000 - val_loss: 0.4871 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.6412 - accuracy: 0.6000 - val_loss: 0.4957 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.6433 - accuracy: 0.6000 - val_loss: 0.4892 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.6412 - accuracy: 0.6000 - val_loss: 0.4830 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.6317 - accuracy: 0.6000 - val_loss: 0.4769 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6325 - accuracy: 0.6000 - val_loss: 0.4861 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6269 - accuracy: 0.6000 - val_loss: 0.4796 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6246 - accuracy: 0.6000 - val_loss: 0.4731 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.6221 - accuracy: 0.6000 - val_loss: 0.4672 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6195 - accuracy: 0.6000 - val_loss: 0.4615 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.6169 - accuracy: 0.6000 - val_loss: 0.4560 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6142 - accuracy: 0.6000 - val_loss: 0.4508 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6115 - accuracy: 0.6000 - val_loss: 0.4456 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.6086 - accuracy: 0.6000 - val_loss: 0.4405 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.6056 - accuracy: 0.6000 - val_loss: 0.4358 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6025 - accuracy: 0.6000 - val_loss: 0.4313 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5992 - accuracy: 0.6000 - val_loss: 0.4270 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.5986 - accuracy: 0.6000 - val_loss: 0.4373 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5938 - accuracy: 0.6000 - val_loss: 0.4462 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5866 - accuracy: 0.6000 - val_loss: 0.4405 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.5856 - accuracy: 0.6000 - val_loss: 0.4502 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5851 - accuracy: 0.6000 - val_loss: 0.4439 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5769 - accuracy: 0.6000 - val_loss: 0.4530 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5722 - accuracy: 0.6000 - val_loss: 0.4616 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5646 - accuracy: 0.6000 - val_loss: 0.4541 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.5624 - accuracy: 0.6000 - val_loss: 0.4612 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5545 - accuracy: 0.6000 - val_loss: 0.4533 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.5519 - accuracy: 0.6000 - val_loss: 0.4600 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5438 - accuracy: 0.6000 - val_loss: 0.4519 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.5410 - accuracy: 0.6000 - val_loss: 0.4601 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5393 - accuracy: 0.6000 - val_loss: 0.4514 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5333 - accuracy: 0.6000 - val_loss: 0.4428 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5235 - accuracy: 0.6000 - val_loss: 0.4492 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5175 - accuracy: 0.6000 - val_loss: 0.4569 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.5112 - accuracy: 0.6000 - val_loss: 0.4619 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5021 - accuracy: 0.6000 - val_loss: 0.4526 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4983 - accuracy: 0.6000 - val_loss: 0.4602 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4916 - accuracy: 0.8000 - val_loss: 0.4649 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4849 - accuracy: 0.8000 - val_loss: 0.4691 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4780 - accuracy: 0.8000 - val_loss: 0.4730 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.4744 - accuracy: 0.8000 - val_loss: 0.4620 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4610 - accuracy: 0.8000 - val_loss: 0.4523 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.4560 - accuracy: 0.8000 - val_loss: 0.4564 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.4520 - accuracy: 1.0000 - val_loss: 0.4468 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4412 - accuracy: 0.8000 - val_loss: 0.4511 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4338 - accuracy: 1.0000 - val_loss: 0.4550 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.4244 - accuracy: 1.0000 - val_loss: 0.4461 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4172 - accuracy: 1.0000 - val_loss: 0.4381 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.4120 - accuracy: 1.0000 - val_loss: 0.4428 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4051 - accuracy: 1.0000 - val_loss: 0.4512 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3958 - accuracy: 1.0000 - val_loss: 0.4427 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3887 - accuracy: 1.0000 - val_loss: 0.4353 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3818 - accuracy: 1.0000 - val_loss: 0.4291 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3768 - accuracy: 1.0000 - val_loss: 0.4346 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3695 - accuracy: 1.0000 - val_loss: 0.4398 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3650 - accuracy: 1.0000 - val_loss: 0.4343 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3562 - accuracy: 1.0000 - val_loss: 0.4441 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.3488 - accuracy: 1.0000 - val_loss: 0.4491 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.3417 - accuracy: 1.0000 - val_loss: 0.4542 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3374 - accuracy: 1.0000 - val_loss: 0.4476 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3286 - accuracy: 1.0000 - val_loss: 0.4531 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.3219 - accuracy: 1.0000 - val_loss: 0.4580 - val_accuracy: 0.5000\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3158 - accuracy: 1.0000 - val_loss: 0.4677 - val_accuracy: 0.5000\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3078 - accuracy: 1.0000 - val_loss: 0.4617 - val_accuracy: 0.5000\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3029 - accuracy: 1.0000 - val_loss: 0.4666 - val_accuracy: 0.5000\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2954 - accuracy: 1.0000 - val_loss: 0.4619 - val_accuracy: 0.5000\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2929 - accuracy: 1.0000 - val_loss: 0.4577 - val_accuracy: 0.5000\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.2873 - accuracy: 1.0000 - val_loss: 0.4548 - val_accuracy: 0.5000\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2798 - accuracy: 1.0000 - val_loss: 0.4613 - val_accuracy: 0.5000\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2760 - accuracy: 1.0000 - val_loss: 0.4588 - val_accuracy: 0.5000\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2694 - accuracy: 1.0000 - val_loss: 0.4704 - val_accuracy: 0.5000\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2636 - accuracy: 1.0000 - val_loss: 0.4815 - val_accuracy: 0.5000\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2567 - accuracy: 1.0000 - val_loss: 0.4780 - val_accuracy: 0.5000\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2517 - accuracy: 1.0000 - val_loss: 0.4756 - val_accuracy: 0.5000\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2471 - accuracy: 1.0000 - val_loss: 0.4735 - val_accuracy: 0.5000\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2436 - accuracy: 1.0000 - val_loss: 0.4855 - val_accuracy: 0.5000\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2382 - accuracy: 1.0000 - val_loss: 0.4971 - val_accuracy: 0.5000\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2328 - accuracy: 1.0000 - val_loss: 0.5033 - val_accuracy: 0.5000\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2273 - accuracy: 1.0000 - val_loss: 0.5013 - val_accuracy: 0.5000\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2241 - accuracy: 1.0000 - val_loss: 0.5127 - val_accuracy: 0.5000\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2183 - accuracy: 1.0000 - val_loss: 0.5104 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, y_train,\n",
    "                  batch_size = batch_size,\n",
    "                  epochs = nb_epoch, \n",
    "                  validation_data = (X_test, y_test),\n",
    "                  verbose=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "234c4b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(hist.history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30617af0",
   "metadata": {},
   "source": [
    "## >**To be Continued...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "19265317",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d8ff87",
   "metadata": {},
   "source": [
    "## Applying  LSTM model to classify the protein function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c8f6a3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(units=128, dropout_rate=0.0, learning_rate=0.001, decay_rate=0.0, momentum=0.0, activation='relu', recurrent_activation='sigmoid', loss='binary_crossentropy'):\n",
    "    lstm = Sequential()\n",
    "    lstm.add(LSTM(units, return_sequences=True, input_shape=(None, 500), activation=activation, recurrent_activation=recurrent_activation))\n",
    "    lstm.add(LSTM(units, activation=activation, recurrent_activation=recurrent_activation))\n",
    "    lstm.add(Dropout(dropout_rate))\n",
    "    lstm.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Combine the CNN and LSTM\n",
    "    model = Sequential()\n",
    "    model.add(lstm)\n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = Adam(learning_rate=learning_rate, decay=decay_rate)\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy', tf.keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da09487",
   "metadata": {},
   "source": [
    "### Create a KerasClassifier wrapper for the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "75ad278e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RG\\AppData\\Local\\Temp\\ipykernel_12088\\975172364.py:2: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  lstm_classifier = KerasClassifier(build_fn=create_model, epochs=10, batch_size=32, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "lstm_classifier = KerasClassifier(build_fn=create_model, epochs=10, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac907d5d",
   "metadata": {},
   "source": [
    "### Define the hyperparameters to search over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4d1687a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "param_grid = {\n",
    "    'units': [64, 128, 256],\n",
    "    'dropout_rate': [0.0, 0.2, 0.5],\n",
    "    'learning_rate': [0.0001, 0.001, 0.01],\n",
    "    'decay_rate': [0.0, 0.01, 0.1],\n",
    "    'momentum': [0.0, 0.2, 0.5],\n",
    "    'activation': ['relu', 'sigmoid'],\n",
    "    'recurrent_activation': ['sigmoid', 'tanh'],\n",
    "    'loss': ['binary_crossentropy', 'mse']\n",
    "}\n",
    "# Define the early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cc9ab0",
   "metadata": {},
   "source": [
    "### Perform the randomized search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0a0c8773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best hyperparameters: {'units': 64, 'recurrent_activation': 'tanh', 'momentum': 0.5, 'loss': 'mse', 'learning_rate': 0.001, 'dropout_rate': 0.2, 'decay_rate': 0.0, 'activation': 'relu'}\n",
      "Best score: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# Perform the randomized search\n",
    "search = RandomizedSearchCV(lstm_classifier, param_grid, n_iter=10, cv=3, verbose=1, n_jobs=-1)\n",
    "search.fit(X_train, y_train, validation_split=0.2, shuffle=True)\n",
    "\n",
    "# Print the best hyperparameters and corresponding performance\n",
    "print('Best hyperparameters:', search.best_params_)\n",
    "print('Best score:', search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0ac75738",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = search.best_estimator_.model.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "01b3c461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = range(1, len(history.history['loss']) + 1)\n",
    "plt.plot(epochs, history.history['loss'], label='Training loss')\n",
    "plt.plot(epochs, history.history['val_loss'], label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10a10f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predictions on the test data\n",
    "y_pred = bidirectional_lstm.predict(X_test)\n",
    "\n",
    "# Visualize the model's predictions\n",
    "plt.plot(y_test, label='True values')\n",
    "plt.plot(y_pred, label='Predicted values')\n",
    "plt.title('True vs. predicted values')\n",
    "plt.xlabel('Samples')\n",
    "plt.ylabel('Class')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d89f1df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0  0  0 ...  4  1 13]]\n",
      "\n",
      " [[ 0  0  0 ...  2  2 15]]\n",
      "\n",
      " [[ 0  0  0 ... 11  2  7]]\n",
      "\n",
      " [[ 0  0  0 ...  9  3 15]]\n",
      "\n",
      " [[ 0  0  0 ... 11  2  7]]]\n",
      "[1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1333a099",
   "metadata": {},
   "source": [
    "## Applying  LSTM Bidirectional to classify the protein function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "400d74d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Bidirectional\n",
    "bidirectional_lstm = Sequential()\n",
    "bidirectional_lstm.add(Bidirectional(LSTM(128, return_sequences=True), input_shape =(None,500)))\n",
    "bidirectional_lstm.add(Bidirectional(LSTM(64)))\n",
    "bidirectional_lstm.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "394f1a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(bidirectional_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5cfd9f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a55bf71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 17s 2s/step - loss: 0.7506 - accuracy: 0.2000 - val_loss: 0.6844 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.3864 - accuracy: 1.0000 - val_loss: 0.6999 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.2489 - accuracy: 1.0000 - val_loss: 0.7075 - val_accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.1623 - accuracy: 1.0000 - val_loss: 0.7451 - val_accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.1054 - accuracy: 1.0000 - val_loss: 0.8114 - val_accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0693 - accuracy: 1.0000 - val_loss: 0.8953 - val_accuracy: 0.5000\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.0448 - accuracy: 1.0000 - val_loss: 0.9896 - val_accuracy: 0.5000\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 1.1694 - val_accuracy: 0.5000\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 1.2962 - val_accuracy: 0.5000\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 1.4013 - val_accuracy: 0.5000\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 1.5018 - val_accuracy: 0.5000\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 1.6014 - val_accuracy: 0.5000\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.6898 - val_accuracy: 0.5000\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.7691 - val_accuracy: 0.5000\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.8523 - val_accuracy: 0.5000\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.9481 - val_accuracy: 0.5000\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.0052 - val_accuracy: 0.5000\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.0605 - val_accuracy: 0.5000\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.1102 - val_accuracy: 0.5000\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.1567 - val_accuracy: 0.5000\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.1993 - val_accuracy: 0.5000\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.2361 - val_accuracy: 0.5000\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.2684 - val_accuracy: 0.5000\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.2992 - val_accuracy: 0.5000\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.3282 - val_accuracy: 0.5000\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.3536 - val_accuracy: 0.5000\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.3765 - val_accuracy: 0.5000\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.3982 - val_accuracy: 0.5000\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.4278 - val_accuracy: 0.5000\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.4488 - val_accuracy: 0.5000\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.4677 - val_accuracy: 0.5000\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.4856 - val_accuracy: 0.5000\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.5020 - val_accuracy: 0.5000\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.5182 - val_accuracy: 0.5000\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.5338 - val_accuracy: 0.5000\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.5502 - val_accuracy: 0.5000\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.5653 - val_accuracy: 0.5000\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.5803 - val_accuracy: 0.5000\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 9.8805e-04 - accuracy: 1.0000 - val_loss: 2.5943 - val_accuracy: 0.5000\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 9.5851e-04 - accuracy: 1.0000 - val_loss: 2.6097 - val_accuracy: 0.5000\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 9.2719e-04 - accuracy: 1.0000 - val_loss: 2.6243 - val_accuracy: 0.5000\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 8.9580e-04 - accuracy: 1.0000 - val_loss: 2.6380 - val_accuracy: 0.5000\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 8.7034e-04 - accuracy: 1.0000 - val_loss: 2.6529 - val_accuracy: 0.5000\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 8.4315e-04 - accuracy: 1.0000 - val_loss: 2.6672 - val_accuracy: 0.5000\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 8.1582e-04 - accuracy: 1.0000 - val_loss: 2.6811 - val_accuracy: 0.5000\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 7.9106e-04 - accuracy: 1.0000 - val_loss: 2.6964 - val_accuracy: 0.5000\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 7.6676e-04 - accuracy: 1.0000 - val_loss: 2.7121 - val_accuracy: 0.5000\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 7.4508e-04 - accuracy: 1.0000 - val_loss: 2.7268 - val_accuracy: 0.5000\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 7.2023e-04 - accuracy: 1.0000 - val_loss: 2.7398 - val_accuracy: 0.5000\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 7.0202e-04 - accuracy: 1.0000 - val_loss: 2.7532 - val_accuracy: 0.5000\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 6.8146e-04 - accuracy: 1.0000 - val_loss: 2.7654 - val_accuracy: 0.5000\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 6.6311e-04 - accuracy: 1.0000 - val_loss: 2.7773 - val_accuracy: 0.5000\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 6.4597e-04 - accuracy: 1.0000 - val_loss: 2.7886 - val_accuracy: 0.5000\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 6.2834e-04 - accuracy: 1.0000 - val_loss: 2.7990 - val_accuracy: 0.5000\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 6.1223e-04 - accuracy: 1.0000 - val_loss: 2.8094 - val_accuracy: 0.5000\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 5.9577e-04 - accuracy: 1.0000 - val_loss: 2.8208 - val_accuracy: 0.5000\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 5.8027e-04 - accuracy: 1.0000 - val_loss: 2.8318 - val_accuracy: 0.5000\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 5.6726e-04 - accuracy: 1.0000 - val_loss: 2.8437 - val_accuracy: 0.5000\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 5.5293e-04 - accuracy: 1.0000 - val_loss: 2.8549 - val_accuracy: 0.5000\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 5.3971e-04 - accuracy: 1.0000 - val_loss: 2.8665 - val_accuracy: 0.5000\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 5.2752e-04 - accuracy: 1.0000 - val_loss: 2.8783 - val_accuracy: 0.5000\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 5.1493e-04 - accuracy: 1.0000 - val_loss: 2.8889 - val_accuracy: 0.5000\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 5.0236e-04 - accuracy: 1.0000 - val_loss: 2.8984 - val_accuracy: 0.5000\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 4.9031e-04 - accuracy: 1.0000 - val_loss: 2.9069 - val_accuracy: 0.5000\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 4.7938e-04 - accuracy: 1.0000 - val_loss: 2.9158 - val_accuracy: 0.5000\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 4.6727e-04 - accuracy: 1.0000 - val_loss: 2.9253 - val_accuracy: 0.5000\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 4.5676e-04 - accuracy: 1.0000 - val_loss: 2.9351 - val_accuracy: 0.5000\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 4.4756e-04 - accuracy: 1.0000 - val_loss: 2.9455 - val_accuracy: 0.5000\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 4.3744e-04 - accuracy: 1.0000 - val_loss: 2.9534 - val_accuracy: 0.5000\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 4.2718e-04 - accuracy: 1.0000 - val_loss: 2.9607 - val_accuracy: 0.5000\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 4.1547e-04 - accuracy: 1.0000 - val_loss: 2.9689 - val_accuracy: 0.5000\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 4.0433e-04 - accuracy: 1.0000 - val_loss: 2.9780 - val_accuracy: 0.5000\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 3.9426e-04 - accuracy: 1.0000 - val_loss: 2.9867 - val_accuracy: 0.5000\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 3.8491e-04 - accuracy: 1.0000 - val_loss: 2.9955 - val_accuracy: 0.5000\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 3.7685e-04 - accuracy: 1.0000 - val_loss: 3.0045 - val_accuracy: 0.5000\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 3.6917e-04 - accuracy: 1.0000 - val_loss: 3.0133 - val_accuracy: 0.5000\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 3.6203e-04 - accuracy: 1.0000 - val_loss: 3.0229 - val_accuracy: 0.5000\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 3.5527e-04 - accuracy: 1.0000 - val_loss: 3.0330 - val_accuracy: 0.5000\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 3.4831e-04 - accuracy: 1.0000 - val_loss: 3.0435 - val_accuracy: 0.5000\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 3.4156e-04 - accuracy: 1.0000 - val_loss: 3.0538 - val_accuracy: 0.5000\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 3.3470e-04 - accuracy: 1.0000 - val_loss: 3.0640 - val_accuracy: 0.5000\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 3.2861e-04 - accuracy: 1.0000 - val_loss: 3.0745 - val_accuracy: 0.5000\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 3.2268e-04 - accuracy: 1.0000 - val_loss: 3.0850 - val_accuracy: 0.5000\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 3.1659e-04 - accuracy: 1.0000 - val_loss: 3.0951 - val_accuracy: 0.5000\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 3.1044e-04 - accuracy: 1.0000 - val_loss: 3.1047 - val_accuracy: 0.5000\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 3.0571e-04 - accuracy: 1.0000 - val_loss: 3.1147 - val_accuracy: 0.5000\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 2.9975e-04 - accuracy: 1.0000 - val_loss: 3.1239 - val_accuracy: 0.5000\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 2.9457e-04 - accuracy: 1.0000 - val_loss: 3.1331 - val_accuracy: 0.5000\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 2.8926e-04 - accuracy: 1.0000 - val_loss: 3.1423 - val_accuracy: 0.5000\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 2.8453e-04 - accuracy: 1.0000 - val_loss: 3.1516 - val_accuracy: 0.5000\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 2.7968e-04 - accuracy: 1.0000 - val_loss: 3.1604 - val_accuracy: 0.5000\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 2.7486e-04 - accuracy: 1.0000 - val_loss: 3.1693 - val_accuracy: 0.5000\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 2.7020e-04 - accuracy: 1.0000 - val_loss: 3.1780 - val_accuracy: 0.5000\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 2.6570e-04 - accuracy: 1.0000 - val_loss: 3.1864 - val_accuracy: 0.5000\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 2.6113e-04 - accuracy: 1.0000 - val_loss: 3.1943 - val_accuracy: 0.5000\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 2.5707e-04 - accuracy: 1.0000 - val_loss: 3.2024 - val_accuracy: 0.5000\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 2.5285e-04 - accuracy: 1.0000 - val_loss: 3.2098 - val_accuracy: 0.5000\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 2.4901e-04 - accuracy: 1.0000 - val_loss: 3.2171 - val_accuracy: 0.5000\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 2.4503e-04 - accuracy: 1.0000 - val_loss: 3.2240 - val_accuracy: 0.5000\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 2.4150e-04 - accuracy: 1.0000 - val_loss: 3.2314 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22315d5ed60>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train, y_train,\n",
    "                  batch_size = batch_size,\n",
    "                  epochs = nb_epoch, \n",
    "                  validation_data = (X_test, y_test), verbose= 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
